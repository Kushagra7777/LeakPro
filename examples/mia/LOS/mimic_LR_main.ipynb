{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# MIA attacks on Length-of-Stay predictor, Logistic Regression\n",
            "## Installation of Packages in Conda\n",
            "\n",
            "To install the required packages in your conda environment, you can use the following commands:\n",
            "\n",
            "```bash\n",
            "conda install h5py\n",
            "conda install pytables\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import sys\n",
            "\n",
            "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
            "sys.path.append(project_root)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Train the classifier\n",
            "For the LR, the data should be flatten. So set the value to True for the LR model anb False for the GRU-D"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Load the dataset\n",
            "The dataset is generated by the notebook file ...."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Loading dataset...\n",
                  "Loaded dataset from ./data/LR_data/dataset.pkl\n"
               ]
            }
         ],
         "source": [
            "import yaml\n",
            "import pickle\n",
            "\n",
            "# Load the config.yaml file\n",
            "with open('train_config.yaml', 'r') as file:\n",
            "    train_config = yaml.safe_load(file)\n",
            "\n",
            "use_LR = train_config['train']['training_method'] == 'LR'\n",
            "data_path = train_config['data']['data_dir']\n",
            "\n",
            "if use_LR:\n",
            "    path = data_path + \"LR_data/\"\n",
            "else:\n",
            "    path = data_path + \"GRUD_data/\"\n",
            "\n",
            "dataset_path = os.path.join(path, \"dataset.pkl\")\n",
            "\n",
            "if os.path.exists(dataset_path):\n",
            "        print(\"Loading dataset...\")\n",
            "        with open(dataset_path, \"rb\") as f:\n",
            "            population_dataset = pickle.load(f)  # Load the dataset\n",
            "        print(f\"Loaded dataset from {dataset_path}\")\n",
            "else:\n",
            "    print(\"\\nDataset not found.\\nâ†’ Run 'mimic_dataset_prep.ipynb' to generate the required dataset.\\n\")\n",
            "\n",
            "data, targets = population_dataset.x, population_dataset.y"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "ename": "NameError",
               "evalue": "name 'data' is not defined",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m selected_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(dataset_size), train_size \u001b[38;5;241m+\u001b[39m test_size, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m train_indices, test_indices \u001b[38;5;241m=\u001b[39m train_test_split(selected_index, test_size\u001b[38;5;241m=\u001b[39mtest_size)\n\u001b[0;32m---> 17\u001b[0m train_subset \u001b[38;5;241m=\u001b[39m MIMICInputHandler\u001b[38;5;241m.\u001b[39mUserDataset(\u001b[43mdata\u001b[49m[train_indices], targets[train_indices])\n\u001b[1;32m     18\u001b[0m test_subset \u001b[38;5;241m=\u001b[39m MIMICInputHandler\u001b[38;5;241m.\u001b[39mUserDataset(data[test_indices], targets[test_indices], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrain_subset\u001b[38;5;241m.\u001b[39mreturn_params())\n",
                  "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
               ]
            }
         ],
         "source": [
            "from sklearn.model_selection import train_test_split\n",
            "from torch.utils.data import DataLoader\n",
            "import numpy as np\n",
            "from mimic_handler import MIMICInputHandler\n",
            "\n",
            "train_fraction = train_config[\"data\"][\"f_train\"]\n",
            "test_fraction = train_config[\"data\"][\"f_test\"]\n",
            "batch_size = train_config[\"data\"][\"batch_size\"]\n",
            "\n",
            "dataset_size = len(population_dataset)\n",
            "train_size = int(train_fraction * dataset_size)\n",
            "test_size = int(test_fraction * dataset_size)\n",
            "\n",
            "selected_index = np.random.choice(np.arange(dataset_size), train_size + test_size, replace=False)\n",
            "train_indices, test_indices = train_test_split(selected_index, test_size=test_size)\n",
            "\n",
            "train_subset = MIMICInputHandler.UserDataset(data[train_indices], targets[train_indices])\n",
            "test_subset = MIMICInputHandler.UserDataset(data[test_indices], targets[test_indices], **train_subset.return_params())\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from utils.data_processing import get_mimic_dataloaders, get_mimic_dataset\n",
            "\n",
            "\n",
            "# Generate the dataset and dataloaders\n",
            "path = os.path.join(os.getcwd(), \"data/\")\n",
            "use_LR = True # If True, use a logistic regression model. If False, use a GRUD model.\n",
            "dataset, train_indices, validation_indices, test_indices, early_stop_indices = get_mimic_dataset(path, train_frac = 0.3,\n",
            "                                                                            test_frac = 0.2,\n",
            "                                                                            validation_frac = 0,\n",
            "                                                                            early_stop_frac = 0,\n",
            "                                                                            use_LR = use_LR)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "train_loader, validation_loader, test_loader, early_stop_loader = get_mimic_dataloaders(dataset,\n",
            "                          train_indices,\n",
            "                          validation_indices,\n",
            "                          test_indices,\n",
            "                          early_stop_indices,\n",
            "                          batch_size=128)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from utils.model_LR import LR, create_trained_model_and_metadata\n",
            "n_features = dataset.x.shape[1]\n",
            "print(f\"Number of features: {n_features}\")\n",
            "\n",
            "model = LR(n_features)\n",
            "train_acc, train_loss, test_acc, test_loss = create_trained_model_and_metadata(model,\n",
            "                                                                               train_loader,\n",
            "                                                                               test_loader,\n",
            "                                                                               lr = 0.0001,\n",
            "                                                                               weight_decay = 5.392,\n",
            "                                                                               epochs=20)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Plot training and test accuracy\n",
            "plt.figure(figsize=(5, 4))\n",
            "\n",
            "plt.subplot(1, 2, 1)\n",
            "plt.plot(train_acc, label=\"Train Accuracy\")\n",
            "plt.plot(test_acc, label=\"Test Accuracy\")\n",
            "plt.xlabel(\"Epoch\")\n",
            "plt.ylabel(\"Accuracy\")\n",
            "plt.title(\"Accuracy over Epochs\")\n",
            "plt.legend()\n",
            "\n",
            "# Plot training and test loss\n",
            "plt.subplot(1, 2, 2)\n",
            "plt.plot(train_loss, label=\"Train Loss\")\n",
            "plt.plot(test_loss, label=\"Test Loss\")\n",
            "plt.xlabel(\"Epoch\")\n",
            "plt.ylabel(\"Loss\")\n",
            "plt.title(\"Loss over Epochs\")\n",
            "plt.legend()\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Attack the LR model\n",
            "Modify ```audit.yaml ``` file to attack LR model: \n",
            "  \n",
            "  ```\n",
            "  module_path: \"utils/model_LR.py\" \n",
            "  model_class: \"LR\"\n",
            "  target_folder: \"./target_LR\"\n",
            "  data_path: \"./data/LR_data/dataset.pkl\"\n",
            "  ```\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from mimic_LR_handler import MimicInputHandler\n",
            "\n",
            "from leakpro import LeakPro\n",
            "\n",
            "# Read the config file\n",
            "config_path = \"audit.yaml\"\n",
            "\n",
            "# Prepare leakpro object\n",
            "leakpro = LeakPro(MimicInputHandler, config_path)\n",
            "\n",
            "# Run the audit\n",
            "mia_results = leakpro.run_audit(return_results=True)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Generate report"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Import and initialize ReportHandler\n",
            "from leakpro.reporting.report_handler import ReportHandler\n",
            "\n",
            "# report_handler = ReportHandler()\n",
            "report_handler = ReportHandler(report_dir=\"./leakpro_output/results\")\n",
            "\n",
            "# Save MIA resuls using report handler\n",
            "for res in mia_results:\n",
            "    report_handler.save_results(attack_name=res.attack_name, result_data=res, config=res.configs)\n",
            "\n",
            "# # Create the report by compiling the latex text\n",
            "report_handler.create_report()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".leakpro_dev",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.11"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
