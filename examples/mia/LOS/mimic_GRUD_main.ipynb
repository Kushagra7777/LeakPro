{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIA attacks on Length-of-Stay predictor, Gated Recurrent Unit with Decay (GRU-D)\n",
    "## Installation of Packages in Conda\n",
    "\n",
    "To install the required packages in your conda environment, you can use the following commands:\n",
    "\n",
    "```bash\n",
    "conda install h5py\n",
    "conda install pytables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch import zeros\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils.data_processing import get_mimic_dataloaders, get_mimic_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  `batch_size` is one of the parameters which is assigned based on hyperparameter tuning as detailed in [this notebook](https://github.com/MLforHealth/MIMIC_Extract/blob/4daf3c89be7de05d26f47819d68d5532de6f753a/notebooks/Baselines%20for%20Mortality%20and%20LOS%20prediction%20-%20GRU-D.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset and dataloaders\n",
    "path = os.path.join(os.getcwd(), \"data/\")\n",
    "\n",
    "train_frac = 0.4\n",
    "valid_frac = 0.0\n",
    "test_frac = 0.0\n",
    "early_stop_frac = 0.4\n",
    "batch_size = 74\n",
    "use_LR = False # True if you want to use the LR model, False if you want to use the GRUD model\n",
    "\n",
    "dataset, train_indices, validation_indices, test_indices, early_stop_indices= get_mimic_dataset(path,\n",
    "                                                                            train_frac ,\n",
    "                                                                            valid_frac,\n",
    "                                                                            test_frac,\n",
    "                                                                            early_stop_frac,\n",
    "                                                                            use_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, validation_loader, test_loader, early_stop_loader = get_mimic_dataloaders(dataset,\n",
    "                                                            train_indices,\n",
    "                                                            validation_indices,\n",
    "                                                            test_indices,\n",
    "                                                            early_stop_indices,\n",
    "                                                            batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `optimized_hyperparams` is assigned based on hyperparameter tuning as detailed in [this notebook](https://github.com/MLforHealth/MIMIC_Extract/blob/4daf3c89be7de05d26f47819d68d5532de6f753a/notebooks/Baselines%20for%20Mortality%20and%20LOS%20prediction%20-%20GRU-D.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_hyperparams ={\n",
    "    \"hidden_size\": 27,\n",
    "    \"learning_rate\": 0.000289,\n",
    "    \"num_epochs\":40,\n",
    "    \"patience_early_stopping\": 40,\n",
    "    \"patience_lr_scheduler\": 2,\n",
    "    \"batch_size\": 74,\n",
    "    \"seed\": 6286,\n",
    "    \"min_delta\": 0.00001,\n",
    "    }\n",
    "\n",
    "n_features = int(dataset.x.shape[1]/3)\n",
    "X_mean = zeros(1,dataset.x.shape[2],n_features)\n",
    "\n",
    "# Add other required parameters to model_params\n",
    "model_params = {\n",
    "    \"hidden_size\": optimized_hyperparams[\"hidden_size\"],\n",
    "    \"batch_size\": optimized_hyperparams[\"batch_size\"],\n",
    "    \"input_size\": n_features,\n",
    "    \"X_mean\": X_mean,\n",
    "    \"output_last\": False,\n",
    "    \"bn_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_GRUD import *\n",
    "\n",
    "# Initialize the model with filtered parameters\n",
    "model = GRUD(**model_params)\n",
    "\n",
    "# Train the model with Train_Model function\n",
    "train_losses, test_losses , train_acc, test_acc = gru_trained_model_and_metadata(model,\n",
    "                                                                                train_loader,\n",
    "                                                                                early_stop_loader,\n",
    "                                                                                epochs = optimized_hyperparams[\"num_epochs\"],\n",
    "                                                                                patience_early_stopping = optimized_hyperparams[\"patience_early_stopping\"],\n",
    "                                                                                patience_lr= optimized_hyperparams[\"patience_lr_scheduler\"],\n",
    "                                                                                min_delta = optimized_hyperparams[\"min_delta\"],\n",
    "                                                                                learning_rate = optimized_hyperparams[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert losses to numpy-compatible lists directly\n",
    "train_losses_cpu = [float(loss) for loss in train_losses]\n",
    "test_losses_cpu = [float(loss) for loss in test_losses]\n",
    "\n",
    "# Plot training and test accuracy\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label=\"Train Accuracy\")\n",
    "plt.plot(test_acc, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and test loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Attacking the GRUD model\n",
    "Modify ```audit.yaml ``` file to attack GRUD model: \n",
    "  \n",
    "  ```\n",
    "  module_path: \"utils/model_GRUD.py\" \n",
    "  model_class: \"GRUD\"\n",
    "  target_folder: \"./target_GRUD\"\n",
    "  data_path: \"./data/GRUD_data/dataset.pkl\"\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimic_GRUD_handler import MimicInputHandlerGRU\n",
    "\n",
    "from leakpro import LeakPro\n",
    "\n",
    "# Read the config file\n",
    "config_path = \"audit.yaml\"\n",
    "\n",
    "# Prepare leakpro object\n",
    "leakpro = LeakPro(MimicInputHandlerGRU, config_path)\n",
    "\n",
    "# Run the audit\n",
    "mia_results = leakpro.run_audit(return_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import and initialize ReportHandler\n",
    "from leakpro.reporting.report_handler import ReportHandler\n",
    "\n",
    "# report_handler = ReportHandler()\n",
    "report_handler = ReportHandler(report_dir=\"./leakpro_output/results\")\n",
    "\n",
    "# Save MIA resuls using report handler\n",
    "for res in mia_results:\n",
    "    report_handler.save_results(attack_name=res.attack_name, result_data=res, config=res.configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the report by compiling the latex text\n",
    "report_handler.create_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".leakpro_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
