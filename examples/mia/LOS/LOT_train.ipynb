{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LOT perdiciton Model Training\n",
    "The task is to predict if the LOS > 3 Days by logistic regression.\n",
    "\n",
    "This document is a based on [this code](https://github.com/MLforHealth/MIMIC_Extract/blob/master/notebooks/Baselines%20for%20Mortality%20and%20LOS%20prediction%20-%20Sklearn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9392ed1fc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FILEPATH     = './mimic_data/final/grouping_5/all_hourly_data.h5'\n",
    "RAW_DATA_FILEPATH = './mimic_data/final/nogrouping_5/all_hourly_data.h5'\n",
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 1\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '2'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_lvl2 = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "data_full_raw  = pd.read_hdf(RAW_DATA_FILEPATH, 'vitals_labs') \n",
    "statics        = pd.read_hdf(DATA_FILEPATH, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictDist():\n",
    "    def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "    def rvs(self, n):\n",
    "        a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "        out = []\n",
    "        for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "        return out\n",
    "    \n",
    "class Choice():\n",
    "    def __init__(self, options): self.options = options\n",
    "    def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LEVEL2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">alanine aminotransferase</th>\n",
       "      <th colspan=\"3\" halign=\"left\">albumin</th>\n",
       "      <th colspan=\"3\" halign=\"left\">albumin ascites</th>\n",
       "      <th>albumin pleural</th>\n",
       "      <th>...</th>\n",
       "      <th>white blood cell count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">white blood cell count urine</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ph</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ph urine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Aggregation Function</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hours_in</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">145834</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">211552</th>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.012837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.147733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "LEVEL2                                 alanine aminotransferase             \\\n",
       "Aggregation Function                                      count  mean  std   \n",
       "subject_id hadm_id icustay_id hours_in                                       \n",
       "3          145834  211552     0                             2.0  25.0  0.0   \n",
       "                              1                             0.0   NaN  NaN   \n",
       "                              2                             0.0   NaN  NaN   \n",
       "                              3                             0.0   NaN  NaN   \n",
       "                              4                             0.0   NaN  NaN   \n",
       "\n",
       "LEVEL2                                 albumin           albumin ascites       \\\n",
       "Aggregation Function                     count mean  std           count mean   \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0            2.0  1.8  0.0             0.0  NaN   \n",
       "                              1            0.0  NaN  NaN             0.0  NaN   \n",
       "                              2            0.0  NaN  NaN             0.0  NaN   \n",
       "                              3            0.0  NaN  NaN             0.0  NaN   \n",
       "                              4            0.0  NaN  NaN             0.0  NaN   \n",
       "\n",
       "LEVEL2                                     albumin pleural  ...  \\\n",
       "Aggregation Function                   std           count  ...   \n",
       "subject_id hadm_id icustay_id hours_in                      ...   \n",
       "3          145834  211552     0        NaN             0.0  ...   \n",
       "                              1        NaN             0.0  ...   \n",
       "                              2        NaN             0.0  ...   \n",
       "                              3        NaN             0.0  ...   \n",
       "                              4        NaN             0.0  ...   \n",
       "\n",
       "LEVEL2                                 white blood cell count  \\\n",
       "Aggregation Function                                      std   \n",
       "subject_id hadm_id icustay_id hours_in                          \n",
       "3          145834  211552     0                      4.012837   \n",
       "                              1                           NaN   \n",
       "                              2                           NaN   \n",
       "                              3                           NaN   \n",
       "                              4                           NaN   \n",
       "\n",
       "LEVEL2                                 white blood cell count urine           \\\n",
       "Aggregation Function                                          count mean std   \n",
       "subject_id hadm_id icustay_id hours_in                                         \n",
       "3          145834  211552     0                                 0.0  NaN NaN   \n",
       "                              1                                 0.0  NaN NaN   \n",
       "                              2                                 0.0  NaN NaN   \n",
       "                              3                                 0.0  NaN NaN   \n",
       "                              4                                 0.0  NaN NaN   \n",
       "\n",
       "LEVEL2                                    ph                 ph urine           \n",
       "Aggregation Function                   count  mean       std    count mean std  \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0          9.0  7.40  0.147733      1.0  5.0 NaN  \n",
       "                              1          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "                              2          3.0  7.26  0.000000      0.0  NaN NaN  \n",
       "                              3          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "                              4          0.0   NaN       NaN      0.0  NaN NaN  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_lvl2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th colspan=\"3\" halign=\"left\">51</th>\n",
       "      <th colspan=\"3\" halign=\"left\">52</th>\n",
       "      <th colspan=\"3\" halign=\"left\">89</th>\n",
       "      <th>90</th>\n",
       "      <th>...</th>\n",
       "      <th>227465</th>\n",
       "      <th colspan=\"3\" halign=\"left\">227466</th>\n",
       "      <th colspan=\"3\" halign=\"left\">227467</th>\n",
       "      <th colspan=\"3\" halign=\"left\">227468</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th colspan=\"3\" halign=\"left\">arterial bp [systolic]</th>\n",
       "      <th colspan=\"3\" halign=\"left\">arterial bp mean</th>\n",
       "      <th colspan=\"3\" halign=\"left\">c.o. (fick)</th>\n",
       "      <th>c.o.(thermodilution)</th>\n",
       "      <th>...</th>\n",
       "      <th>prothrombin time</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ptt</th>\n",
       "      <th colspan=\"3\" halign=\"left\">inr</th>\n",
       "      <th colspan=\"3\" halign=\"left\">fibrinogen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LEVEL1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">systolic blood pressure (arterial)</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mean blood pressure (arterial)</th>\n",
       "      <th colspan=\"3\" halign=\"left\">cardiac output fick</th>\n",
       "      <th>cardiac output thermodilution</th>\n",
       "      <th>...</th>\n",
       "      <th>prothrombin time</th>\n",
       "      <th colspan=\"3\" halign=\"left\">partial thromboplastin time</th>\n",
       "      <th colspan=\"3\" halign=\"left\">prothrombin time</th>\n",
       "      <th colspan=\"3\" halign=\"left\">fibrinogen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LEVEL2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">systolic blood pressure</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mean blood pressure</th>\n",
       "      <th colspan=\"3\" halign=\"left\">cardiac output fick</th>\n",
       "      <th>cardiac output thermodilution</th>\n",
       "      <th>...</th>\n",
       "      <th>prothrombin time pt</th>\n",
       "      <th colspan=\"3\" halign=\"left\">partial thromboplastin time</th>\n",
       "      <th colspan=\"3\" halign=\"left\">prothrombin time inr</th>\n",
       "      <th colspan=\"3\" halign=\"left\">fibrinogen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Aggregation Function</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hours_in</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">145834</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">211552</th>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>55.154329</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.50</td>\n",
       "      <td>140.714249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>77.75</td>\n",
       "      <td>7.088723</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.25</td>\n",
       "      <td>5.123475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>8.185353</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71.00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>117.00</td>\n",
       "      <td>19.714631</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.75</td>\n",
       "      <td>12.230427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>102.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 546 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "itemid                                                                 51  \\\n",
       "label                                              arterial bp [systolic]   \n",
       "LEVEL1                                 systolic blood pressure (arterial)   \n",
       "LEVEL2                                            systolic blood pressure   \n",
       "Aggregation Function                                                count   \n",
       "subject_id hadm_id icustay_id hours_in                                      \n",
       "3          145834  211552     0                                       2.0   \n",
       "                              1                                       4.0   \n",
       "                              2                                       3.0   \n",
       "                              3                                       4.0   \n",
       "                              4                                       1.0   \n",
       "\n",
       "itemid                                                     \\\n",
       "label                                                       \n",
       "LEVEL1                                                      \n",
       "LEVEL2                                                      \n",
       "Aggregation Function                      mean        std   \n",
       "subject_id hadm_id icustay_id hours_in                      \n",
       "3          145834  211552     0          39.00  55.154329   \n",
       "                              1          77.75   7.088723   \n",
       "                              2          91.00   8.185353   \n",
       "                              3         117.00  19.714631   \n",
       "                              4         102.00        NaN   \n",
       "\n",
       "itemid                                                             52          \\\n",
       "label                                                arterial bp mean           \n",
       "LEVEL1                                 mean blood pressure (arterial)           \n",
       "LEVEL2                                            mean blood pressure           \n",
       "Aggregation Function                                            count    mean   \n",
       "subject_id hadm_id icustay_id hours_in                                          \n",
       "3          145834  211552     0                                   2.0  159.50   \n",
       "                              1                                   4.0   60.25   \n",
       "                              2                                   3.0   71.00   \n",
       "                              3                                   4.0   84.75   \n",
       "                              4                                   1.0   77.00   \n",
       "\n",
       "itemid                                                              89       \\\n",
       "label                                                      c.o. (fick)        \n",
       "LEVEL1                                             cardiac output fick        \n",
       "LEVEL2                                             cardiac output fick        \n",
       "Aggregation Function                           std               count mean   \n",
       "subject_id hadm_id icustay_id hours_in                                        \n",
       "3          145834  211552     0         140.714249                 0.0  NaN   \n",
       "                              1           5.123475                 0.0  NaN   \n",
       "                              2           5.000000                 0.0  NaN   \n",
       "                              3          12.230427                 0.0  NaN   \n",
       "                              4                NaN                 0.0  NaN   \n",
       "\n",
       "itemid                                                                90  ...  \\\n",
       "label                                               c.o.(thermodilution)  ...   \n",
       "LEVEL1                                     cardiac output thermodilution  ...   \n",
       "LEVEL2                                     cardiac output thermodilution  ...   \n",
       "Aggregation Function                   std                         count  ...   \n",
       "subject_id hadm_id icustay_id hours_in                                    ...   \n",
       "3          145834  211552     0        NaN                           0.0  ...   \n",
       "                              1        NaN                           0.0  ...   \n",
       "                              2        NaN                           0.0  ...   \n",
       "                              3        NaN                           0.0  ...   \n",
       "                              4        NaN                           0.0  ...   \n",
       "\n",
       "itemid                                              227465  \\\n",
       "label                                     prothrombin time   \n",
       "LEVEL1                                    prothrombin time   \n",
       "LEVEL2                                 prothrombin time pt   \n",
       "Aggregation Function                                   std   \n",
       "subject_id hadm_id icustay_id hours_in                       \n",
       "3          145834  211552     0                        NaN   \n",
       "                              1                        NaN   \n",
       "                              2                        NaN   \n",
       "                              3                        NaN   \n",
       "                              4                        NaN   \n",
       "\n",
       "itemid                                                      227466           \\\n",
       "label                                                          ptt            \n",
       "LEVEL1                                 partial thromboplastin time            \n",
       "LEVEL2                                 partial thromboplastin time            \n",
       "Aggregation Function                                         count mean std   \n",
       "subject_id hadm_id icustay_id hours_in                                        \n",
       "3          145834  211552     0                                0.0  NaN NaN   \n",
       "                              1                                0.0  NaN NaN   \n",
       "                              2                                0.0  NaN NaN   \n",
       "                              3                                0.0  NaN NaN   \n",
       "                              4                                0.0  NaN NaN   \n",
       "\n",
       "itemid                                               227467           \\\n",
       "label                                                   inr            \n",
       "LEVEL1                                     prothrombin time            \n",
       "LEVEL2                                 prothrombin time inr            \n",
       "Aggregation Function                                  count mean std   \n",
       "subject_id hadm_id icustay_id hours_in                                 \n",
       "3          145834  211552     0                         0.0  NaN NaN   \n",
       "                              1                         0.0  NaN NaN   \n",
       "                              2                         0.0  NaN NaN   \n",
       "                              3                         0.0  NaN NaN   \n",
       "                              4                         0.0  NaN NaN   \n",
       "\n",
       "itemid                                     227468           \n",
       "label                                  fibrinogen           \n",
       "LEVEL1                                 fibrinogen           \n",
       "LEVEL2                                 fibrinogen           \n",
       "Aggregation Function                        count mean std  \n",
       "subject_id hadm_id icustay_id hours_in                      \n",
       "3          145834  211552     0               0.0  NaN NaN  \n",
       "                              1               0.0  NaN NaN  \n",
       "                              2               0.0  NaN NaN  \n",
       "                              3               0.0  NaN NaN  \n",
       "                              4               0.0  NaN NaN  \n",
       "\n",
       "[5 rows x 546 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>age</th>\n",
       "      <th>insurance</th>\n",
       "      <th>admittime</th>\n",
       "      <th>diagnosis_at_admission</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>fullcode_first</th>\n",
       "      <th>dnr_first</th>\n",
       "      <th>...</th>\n",
       "      <th>outtime</th>\n",
       "      <th>los_icu</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>first_careunit</th>\n",
       "      <th>mort_icu</th>\n",
       "      <th>mort_hosp</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>hospstay_seq</th>\n",
       "      <th>readmission_30</th>\n",
       "      <th>max_hours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>145834</th>\n",
       "      <th>211552</th>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>76.526792</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>2101-10-20 19:08:00</td>\n",
       "      <td>HYPOTENSION</td>\n",
       "      <td>2101-10-31 13:58:00</td>\n",
       "      <td>SNF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2101-10-26 20:43:09</td>\n",
       "      <td>6.064560</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>185777</th>\n",
       "      <th>294638</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>47.845047</td>\n",
       "      <td>Private</td>\n",
       "      <td>2191-03-16 00:28:00</td>\n",
       "      <td>FEVER,DEHYDRATION,FAILURE TO THRIVE</td>\n",
       "      <td>2191-03-23 18:41:00</td>\n",
       "      <td>HOME WITH HOME IV PROVIDR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2191-03-17 16:46:31</td>\n",
       "      <td>1.678472</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>107064</th>\n",
       "      <th>228232</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>65.942297</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>2175-05-30 07:15:00</td>\n",
       "      <td>CHRONIC RENAL FAILURE/SDA</td>\n",
       "      <td>2175-06-15 16:00:00</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2175-06-03 13:39:54</td>\n",
       "      <td>3.672917</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>SICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>150750</th>\n",
       "      <th>220597</th>\n",
       "      <td>M</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>41.790228</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>2149-11-09 13:06:00</td>\n",
       "      <td>HEMORRHAGIC CVA</td>\n",
       "      <td>2149-11-14 10:15:00</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2149-11-14 20:52:14</td>\n",
       "      <td>5.323056</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>MICU</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>194540</th>\n",
       "      <th>229441</th>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>50.148295</td>\n",
       "      <td>Private</td>\n",
       "      <td>2178-04-16 06:18:00</td>\n",
       "      <td>BRAIN MASS</td>\n",
       "      <td>2178-05-11 19:00:00</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2178-04-17 20:21:05</td>\n",
       "      <td>1.584410</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>SICU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              gender              ethnicity        age  \\\n",
       "subject_id hadm_id icustay_id                                            \n",
       "3          145834  211552          M                  WHITE  76.526792   \n",
       "4          185777  294638          F                  WHITE  47.845047   \n",
       "6          107064  228232          F                  WHITE  65.942297   \n",
       "9          150750  220597          M  UNKNOWN/NOT SPECIFIED  41.790228   \n",
       "11         194540  229441          F                  WHITE  50.148295   \n",
       "\n",
       "                              insurance           admittime  \\\n",
       "subject_id hadm_id icustay_id                                 \n",
       "3          145834  211552      Medicare 2101-10-20 19:08:00   \n",
       "4          185777  294638       Private 2191-03-16 00:28:00   \n",
       "6          107064  228232      Medicare 2175-05-30 07:15:00   \n",
       "9          150750  220597      Medicaid 2149-11-09 13:06:00   \n",
       "11         194540  229441       Private 2178-04-16 06:18:00   \n",
       "\n",
       "                                            diagnosis_at_admission  \\\n",
       "subject_id hadm_id icustay_id                                        \n",
       "3          145834  211552                              HYPOTENSION   \n",
       "4          185777  294638      FEVER,DEHYDRATION,FAILURE TO THRIVE   \n",
       "6          107064  228232                CHRONIC RENAL FAILURE/SDA   \n",
       "9          150750  220597                          HEMORRHAGIC CVA   \n",
       "11         194540  229441                               BRAIN MASS   \n",
       "\n",
       "                                        dischtime         discharge_location  \\\n",
       "subject_id hadm_id icustay_id                                                  \n",
       "3          145834  211552     2101-10-31 13:58:00                        SNF   \n",
       "4          185777  294638     2191-03-23 18:41:00  HOME WITH HOME IV PROVIDR   \n",
       "6          107064  228232     2175-06-15 16:00:00           HOME HEALTH CARE   \n",
       "9          150750  220597     2149-11-14 10:15:00               DEAD/EXPIRED   \n",
       "11         194540  229441     2178-05-11 19:00:00           HOME HEALTH CARE   \n",
       "\n",
       "                               fullcode_first  dnr_first  ...  \\\n",
       "subject_id hadm_id icustay_id                             ...   \n",
       "3          145834  211552                 1.0        0.0  ...   \n",
       "4          185777  294638                 1.0        0.0  ...   \n",
       "6          107064  228232                 1.0        0.0  ...   \n",
       "9          150750  220597                 1.0        0.0  ...   \n",
       "11         194540  229441                 1.0        0.0  ...   \n",
       "\n",
       "                                          outtime   los_icu admission_type  \\\n",
       "subject_id hadm_id icustay_id                                                \n",
       "3          145834  211552     2101-10-26 20:43:09  6.064560      EMERGENCY   \n",
       "4          185777  294638     2191-03-17 16:46:31  1.678472      EMERGENCY   \n",
       "6          107064  228232     2175-06-03 13:39:54  3.672917       ELECTIVE   \n",
       "9          150750  220597     2149-11-14 20:52:14  5.323056      EMERGENCY   \n",
       "11         194540  229441     2178-04-17 20:21:05  1.584410      EMERGENCY   \n",
       "\n",
       "                              first_careunit  mort_icu  mort_hosp  \\\n",
       "subject_id hadm_id icustay_id                                       \n",
       "3          145834  211552               MICU         0          0   \n",
       "4          185777  294638               MICU         0          0   \n",
       "6          107064  228232               SICU         0          0   \n",
       "9          150750  220597               MICU         1          1   \n",
       "11         194540  229441               SICU         0          0   \n",
       "\n",
       "                               hospital_expire_flag hospstay_seq  \\\n",
       "subject_id hadm_id icustay_id                                      \n",
       "3          145834  211552                         0            1   \n",
       "4          185777  294638                         0            1   \n",
       "6          107064  228232                         0            1   \n",
       "9          150750  220597                         1            1   \n",
       "11         194540  229441                         0            1   \n",
       "\n",
       "                              readmission_30 max_hours  \n",
       "subject_id hadm_id icustay_id                           \n",
       "3          145834  211552                  0       145  \n",
       "4          185777  294638                  0        40  \n",
       "6          107064  228232                  0        88  \n",
       "9          150750  220597                  0       127  \n",
       "11         194540  229441                  0        38  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_imputer(df):\n",
    "    idx = pd.IndexSlice\n",
    "    df = df.copy()\n",
    "    if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "    \n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "    \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "    \n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "    \n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "    \n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazeleh/miniconda3/envs/mimic_test/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "\n",
    "lvl2, raw = [df[\n",
    "    (df.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "    (df.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "] for df in (data_full_lvl2, data_full_raw)]\n",
    "\n",
    "raw.columns = raw.columns.droplevel(level=['label', 'LEVEL1', 'LEVEL2'])\n",
    "\n",
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "lvl2_subj_idx, raw_subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (lvl2, raw, Ys)]\n",
    "lvl2_subjects = set(lvl2_subj_idx)\n",
    "assert lvl2_subjects == set(Ys_subj_idx), \"Subject ID pools differ!\"\n",
    "assert lvl2_subjects == set(raw_subj_idx), \"Subject ID pools differ!\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(lvl2_subjects)), len(lvl2_subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]\n",
    "\n",
    "[(lvl2_train, lvl2_dev, lvl2_test), (raw_train, raw_dev, raw_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (lvl2, raw, Ys)\n",
    "]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "lvl2_means, lvl2_stds = lvl2_train.loc[:, idx[:,'mean']].mean(axis=0), lvl2_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "raw_means, raw_stds = raw_train.loc[:, idx[:,'mean']].mean(axis=0), raw_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "lvl2_train.loc[:, idx[:,'mean']] = (lvl2_train.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_dev.loc[:, idx[:,'mean']] = (lvl2_dev.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_test.loc[:, idx[:,'mean']] = (lvl2_test.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "\n",
    "raw_train.loc[:, idx[:,'mean']] = (raw_train.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "raw_dev.loc[:, idx[:,'mean']] = (raw_dev.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "raw_test.loc[:, idx[:,'mean']] = (raw_test.loc[:, idx[:,'mean']] - raw_means)/raw_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If raw or lvl2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazeleh/miniconda3/envs/mimic_test/lib/python3.6/site-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test = [\n",
    "#     simple_imputer(df) for df in (raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test)\n",
    "# ]\n",
    "# raw_flat_train, raw_flat_dev, raw_flat_test, lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "#     df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "#         raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# for df in lvl2_train, lvl2_dev, lvl2_test, raw_train, raw_dev, raw_test: assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fazeleh/miniconda3/envs/mimic_test/lib/python3.6/site-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "lvl2_train, lvl2_dev, lvl2_test = [ simple_imputer(df) for df in ( lvl2_train, lvl2_dev, lvl2_test)]\n",
    "lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], \n",
    "                                                    columns=['hours_in']) for df in (lvl2_train, lvl2_dev, lvl2_test) ]\n",
    "\n",
    "for df in lvl2_train, lvl2_dev, lvl2_test: assert not df.isnull().any().any()\n",
    "for df in lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test: assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group DataFrames in a list\n",
    "# dataframes = [raw_flat_train, raw_flat_dev, raw_flat_test, lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test ]\n",
    "# raw_flat_train.to_csv('raw_flat_train.csv')\n",
    "# raw_flat_dev.to_csv('raw_flat_dev.csv')\n",
    "# raw_flat_test.to_csv('raw_flat_test.csv')\n",
    "# lvl2_flat_train.to_csv('lvl2_flat_train.csv')\n",
    "# lvl2_flat_dev.to_csv('lvl2_flat_dev.csv')\n",
    "# lvl2_flat_test.to_csv('lvl2_flat_test.csv')\n",
    "# Ys_train.to_csv('Ys_train.csv')\n",
    "# Ys_dev.to_csv('Ys_dev.csv')\n",
    "# Ys_test.to_csv('Ys_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_flat_train = pd.read_csv('raw_flat_train.csv', index_col=[0,1,2])\n",
    "# raw_flat_dev = pd.read_csv('raw_flat_dev.csv', index_col=[0,1,2])\n",
    "# raw_flat_test = pd.read_csv('raw_flat_test.csv', index_col=[0,1,2])\n",
    "# lvl2_flat_train = pd.read_csv('lvl2_flat_train.csv', index_col=[0,1,2])\n",
    "# lvl2_flat_dev = pd.read_csv('lvl2_flat_dev.csv', index_col=[0,1,2])\n",
    "# lvl2_flat_test = pd.read_csv('lvl2_flat_test.csv', index_col=[0,1,2])\n",
    "# Ys_train = pd.read_csv('Ys_train.csv', index_col=[0])\n",
    "# Ys_dev = pd.read_csv('Ys_dev.csv', index_col=[0])\n",
    "# Ys_test = pd.read_csv('Ys_test.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of subject_id  hadm_id  icustay_id\n",
       "32          175413   295037         True\n",
       "33          176176   296681        False\n",
       "42          119203   210828        False\n",
       "44          181750   291554         True\n",
       "61          176332   252348        False\n",
       "64          172056   232593        False\n",
       "65          143430   244776         True\n",
       "68          170467   294232         True\n",
       "98          188606   216929        False\n",
       "99          187373   251343        False\n",
       "106         145167   252051         True\n",
       "123         195632   227264        False\n",
       "124         172461   255660         True\n",
       "141         168006   234668         True\n",
       "152         117181   279643        False\n",
       "160         161672   257626        False\n",
       "172         148505   235343        False\n",
       "211         193975   270493         True\n",
       "251         117937   230307        False\n",
       "253         176189   272631        False\n",
       "269         106296   206613         True\n",
       "270         188028   220345        False\n",
       "281         111199   257572         True\n",
       "306         167129   291141        False\n",
       "313         199765   261824         True\n",
       "318         193264   225173         True\n",
       "319         124954   281554        False\n",
       "322         177634   217128        False\n",
       "323         106158   249949         True\n",
       "329         172132   217001         True\n",
       "                                   ...  \n",
       "99286       141676   259289         True\n",
       "99291       186413   275313        False\n",
       "99354       116815   271702        False\n",
       "99364       183367   252720         True\n",
       "99366       136021   218447         True\n",
       "99384       147442   201477        False\n",
       "99408       169240   289644        False\n",
       "99423       174021   277618         True\n",
       "99454       136561   241520        False\n",
       "99458       121483   265252        False\n",
       "99495       129645   229870        False\n",
       "99539       113685   265107        False\n",
       "99560       152883   279885         True\n",
       "99562       129689   246497        False\n",
       "99573       114347   291063        False\n",
       "99598       151312   297993         True\n",
       "99611       108679   205076        False\n",
       "99621       123855   278589        False\n",
       "99629       107034   299480         True\n",
       "99637       198033   257967         True\n",
       "99647       192055   224964         True\n",
       "99650       158023   216378         True\n",
       "99659       175506   212866        False\n",
       "99747       136052   252641         True\n",
       "99752       187858   226190         True\n",
       "99883       150755   276467        False\n",
       "99897       162913   266801        False\n",
       "99913       175989   292375         True\n",
       "99944       185654   221067         True\n",
       "99992       197084   242052        False\n",
       "Name: los_3, Length: 4790, dtype: bool>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ys_test['los_3'].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparams = dict({\n",
    "    'C': 0.18544999360231632,\n",
    "    'penalty': 'l2',\n",
    "    'solver': 'liblinear',\n",
    "    'max_iter': 100\n",
    "})\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_only_final(model, hyperparams, X_flat_train, X_flat_dev, X_flat_test):\n",
    "    best_M = model(**hyperparams)\n",
    "    best_M.fit(pd.concat((X_flat_train, X_flat_dev)), pd.concat((Ys_train, Ys_dev))['los_3'])\n",
    "    y_true  = Ys_test['los_3']\n",
    "    y_score = best_M.predict_proba(X_flat_test)[:, 1]\n",
    "    y_pred  = best_M.predict(X_flat_test)\n",
    "\n",
    "    auc   = roc_auc_score(y_true, y_score)\n",
    "    auprc = average_precision_score(y_true, y_score)\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    F1    = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return best_M, hyperparams, auc, auprc, acc, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_only_final(LogisticRegression,\n",
    "                                hyperparams,\n",
    "                                lvl2_flat_train,\n",
    "                                lvl2_flat_dev,\n",
    "                                lvl2_flat_test) \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to have  pytorch LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488\n",
      "Epoch [1/10], Loss: 43.2495\n",
      "Epoch [3/10], Loss: 43.1651\n",
      "Epoch [5/10], Loss: 43.1667\n",
      "Epoch [7/10], Loss: 43.1655\n",
      "Epoch [9/10], Loss: 43.1659\n",
      "Test Accuracy: 0.5718, Test Loss: 42.8184\n",
      "Train Accuracy: 0.5686, Train Loss: 43.1444\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        \"\"\"Initialize the logistic regression model with a single linear layer.\n",
    "\n",
    "        Args:\n",
    "        ----\n",
    "            input_dim (int): The size of the input feature vector.\n",
    "        \"\"\"\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # Binary classification (1 output)\n",
    "        # Metadata initialization\n",
    "        self.init_params = {\"input_dim\": input_dim}\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the model.\"\"\"\n",
    "        return torch.sigmoid(self.linear(x))  # Sigmoid to produce probabilities for binary classification\n",
    "\n",
    "\n",
    "# Function to save the model and metadata\n",
    "# def save_model_and_metadata(  # noqa: PLR0913\n",
    "#     model: torch.nn.Module,\n",
    "#     data_split: dict,\n",
    "#     configs: dict,\n",
    "#     train_acc: float,\n",
    "#     test_acc: float,\n",
    "#     train_loss: float,\n",
    "#     test_loss: float,\n",
    "#     optimizer: optim.Optimizer,\n",
    "#     loss: nn.Module,\n",
    "#     n: str\n",
    "# ) -> None:\n",
    "#     \"\"\"Save the model and metadata.\"\"\"\n",
    "#     log_dir = configs[\"run\"][\"log_dir\"]\n",
    "#     Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     with open(f\"{log_dir}/target_model\" + n + \".pkl\", \"wb\") as f:\n",
    "#         torch.save(model.state_dict(), f)\n",
    "\n",
    "#     meta_data = {}\n",
    "\n",
    "#     meta_data[\"init_params\"] = model.init_params if hasattr(model, \"init_params\") else {}\n",
    "#     # meta_data[\"train_indices\"] = data_split[\"train_indices\"]\n",
    "#     # meta_data[\"test_indices\"] = data_split[\"test_indices\"]\n",
    "#     # meta_data[\"num_train\"] = len(data_split[\"train_indices\"])\n",
    "\n",
    "#     # read out optimizer parameters\n",
    "#     meta_data[\"optimizer\"] = {}\n",
    "#     meta_data[\"optimizer\"][\"name\"] = optimizer.__class__.__name__.lower()\n",
    "#     meta_data[\"optimizer\"][\"lr\"] = optimizer.param_groups[0].get(\"lr\", 0)\n",
    "#     meta_data[\"optimizer\"][\"weight_decay\"] = optimizer.param_groups[0].get(\"weight_decay\", 0)\n",
    "#     meta_data[\"optimizer\"][\"momentum\"] = optimizer.param_groups[0].get(\"momentum\", 0)\n",
    "#     meta_data[\"optimizer\"][\"dampening\"] = optimizer.param_groups[0].get(\"dampening\", 0)\n",
    "#     meta_data[\"optimizer\"][\"nesterov\"] = optimizer.param_groups[0].get(\"nesterov\", False)\n",
    "\n",
    "#     # read out loss parameters\n",
    "#     meta_data[\"loss\"] = {}\n",
    "#     meta_data[\"loss\"][\"name\"] = loss.__class__.__name__.lower()\n",
    "\n",
    "#     meta_data[\"batch_size\"] = configs[\"train\"][\"batch_size\"]\n",
    "#     meta_data[\"epochs\"] = configs[\"train\"][\"epochs\"]\n",
    "#     meta_data[\"learning_rate\"] = configs[\"train\"][\"learning_rate\"]\n",
    "#     meta_data[\"weight_decay\"] = configs[\"train\"][\"weight_decay\"]\n",
    "#     meta_data[\"train_acc\"] = train_acc\n",
    "#     meta_data[\"test_acc\"] = test_acc\n",
    "#     meta_data[\"train_loss\"] = train_loss\n",
    "#     meta_data[\"test_loss\"] = test_loss\n",
    "#     meta_data[\"dataset\"] = configs[\"data\"][\"dataset\"]\n",
    "\n",
    "#     with open(f\"{log_dir}/model_metadata\"+ n + \".pkl\", \"wb\") as f:\n",
    "#         pickle.dump(meta_data, f)\n",
    "\n",
    "import torch.nn.init as init\n",
    "# Training and evaluation setup\n",
    "def train_and_save_logistic_regression(X_train, y_train, X_test, y_test, configs):\n",
    "    # Convert the inverse regularization parameter C to weight_decay (regularization strength)\n",
    "\n",
    "\n",
    "    # Initialize the model\n",
    "    input_dim = X_train.shape[1]  # Assuming X_train is a NumPy array or similar\n",
    "    print(input_dim)\n",
    "    model = LogisticRegressionModel(input_dim)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr =configs[\"train\"][\"learning_rate\"], \n",
    "                            weight_decay=configs[\"train\"][\"weight_decay\"])\n",
    "\n",
    "    # Training loop (max_iter = number of epochs)\n",
    "    epochs =  configs[\"train\"][\"epochs\"]\n",
    "    batch_size = configs[\"train\"][\"batch_size\"]\n",
    "    \n",
    "    inputs = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    # print(f\"inputs {y_train[:,None].shape}\")\n",
    "    labels = torch.tensor(y_train[:,None], dtype=torch.float32)\n",
    "   \n",
    "    # Create a TensorDataset and DataLoader for batch processing\n",
    "    dataset = TensorDataset(inputs, labels)\n",
    "    batch_size = 128\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        for batch_inputs, batch_labels in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the gradient buffers\n",
    "\n",
    "            outputs = model(batch_inputs)  # Forward pass\n",
    "            loss = criterion(outputs, batch_labels)  # Calculate loss\n",
    "            loss.backward()  # Backward pass\n",
    "\n",
    "            optimizer.step()  # Optimize\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "        \n",
    "        epoch_loss /= len(dataset)\n",
    "        if epoch % 2 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Evaluation on test set\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "        labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "        outputs = model(inputs).squeeze()\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        correct = (predicted == labels).float().sum()\n",
    "        test_acc = correct / len(labels)\n",
    "        test_loss = criterion(outputs, labels).item()\n",
    "\n",
    "    # Calculate training accuracy and loss\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "        outputs = model(inputs).squeeze()\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        correct = (predicted == labels).float().sum()\n",
    "        train_acc = correct / len(labels)\n",
    "        train_loss = criterion(outputs, labels).item()\n",
    "\n",
    "    print(f'Test Accuracy: {test_acc.item():.4f}, Test Loss: {test_loss:.4f}')\n",
    "    print(f'Train Accuracy: {train_acc.item():.4f}, Train Loss: {train_loss:.4f}')\n",
    "    # Save the model and metadata\n",
    "    # save_model_and_metadata(\n",
    "    #     model=model,\n",
    "    #     data_split=data_split,\n",
    "    #     configs=configs,\n",
    "    #     train_acc=train_acc.item(),\n",
    "    #     test_acc=test_acc.item(),\n",
    "    #     train_loss=train_loss,\n",
    "    #     test_loss=test_loss,\n",
    "    #     optimizer=optimizer,\n",
    "    #     loss=criterion,\n",
    "    #     n=n\n",
    "    # )\n",
    "\n",
    "\n",
    "# Example configurations and data split\n",
    "configs = {\n",
    "    \"run\": {\"log_dir\": \"./logs\"},\n",
    "    \"train\": {\"batch_size\": 128, \"epochs\": 10, \"learning_rate\": 0.001, \"weight_decay\": 0.0001},\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "#     ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "#     ('raw', raw_flat_train, raw_flat_dev, raw_flat_test)):\n",
    "    # results = run_only_final(LogisticRegression,\n",
    "    #                             best_hyperparams,\n",
    "    #                             X_flat_train,\n",
    "    #                             X_flat_dev,\n",
    "    #                             X_flat_test,\n",
    "    #                             'los_3')\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "train_and_save_logistic_regression(lvl2_flat_train,\n",
    "                                        Ys_train['los_3'],\n",
    "                                        lvl2_flat_test,\n",
    "                                        Ys_test['los_3'],\n",
    "                                        configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3177983681371872"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0_count = ( Ys_train['los_3'] == 0).sum()  # Count of class 0 samples\n",
    "class_1_count = ( Ys_train['los_3'] == 1).sum()  # Count of class 1 samples\n",
    "pos_weight = class_0_count / class_1_count  # Compute class weight for class 1\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df in lvl2_flat_train, lvl2_flat_test : assert not df.isnull().any().any()\n",
    "lvl2_flat_train.values.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6973\n",
      "Epoch [2/10], Loss: 0.6902\n",
      "Epoch [3/10], Loss: 0.6860\n",
      "Epoch [4/10], Loss: 0.6862\n",
      "Epoch [5/10], Loss: 0.6853\n",
      "Epoch [6/10], Loss: 0.6847\n",
      "Epoch [7/10], Loss: 0.6845\n",
      "Epoch [8/10], Loss: 0.6839\n",
      "Epoch [9/10], Loss: 0.6838\n",
      "Epoch [10/10], Loss: 0.6833\n",
      "Test Accuracy: 0.5718\n"
     ]
    }
   ],
   "source": [
    "class DeepBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepBinaryClassifier, self).__init__()\n",
    "        \n",
    "        # Hidden Layer 1\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)  # Batch Normalization\n",
    "        self.dropout1 = nn.Dropout(0.3)  # Dropout for regularization\n",
    "        \n",
    "        # Hidden Layer 2\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Hidden Layer 3\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Output Layer (Binary Classification)\n",
    "        self.output = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        return self.output(x)  # Do not apply sigmoid here, we will use BCEWithLogitsLoss for stability\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert the dataset to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(lvl2_flat_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor( Ys_train['los_3'], dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(lvl2_flat_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(Ys_test['los_3'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = DeepBinaryClassifier(input_dim =X_train_tensor.shape[1])\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # Combines sigmoid + BCE loss in a stable manner\n",
    "optimizer = optim.Adam(model.parameters(), lr= 0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        outputs = model(X_batch)  # Forward pass\n",
    "        loss = criterion(outputs, y_batch)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    predicted = torch.sigmoid(test_outputs).round()  # Convert logits to probabilities and round\n",
    "    accuracy = (predicted == y_test_tensor).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7488"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
